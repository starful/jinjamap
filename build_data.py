import os
import json
import frontmatter
import markdown
from bs4 import BeautifulSoup  # HTML íƒœê·¸ ì œê±°ìš©
from datetime import datetime

# ì„¤ì •
CONTENT_DIR = 'app/content'
JSON_OUTPUT = 'app/static/json/shrines_data.json'
SITEMAP_OUTPUT = 'app/static/sitemap.xml'
BASE_URL = 'https://jinjamap.com'

def strip_markdown(text):
    """
    ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    1. ë§ˆí¬ë‹¤ìš´ -> HTML ë³€í™˜
    2. HTML -> í…ìŠ¤íŠ¸ ì¶”ì¶œ (íƒœê·¸ ì œê±°)
    """
    try:
        # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜
        html = markdown.markdown(text)
        # BeautifulSoupì„ ì´ìš©í•´ HTML íƒœê·¸ë¥¼ ëª¨ë‘ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        soup = BeautifulSoup(html, "html.parser")
        return soup.get_text()
    except Exception as e:
        print(f"Warning: Text strip failed - {e}")
        return text

def generate_sitemap(shrines):
    """ì‚¬ì´íŠ¸ë§µ XML ë‚´ìš©ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    xml = '<?xml version="1.0" encoding="UTF-8"?>\n'
    xml += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
    
    xml += '  <url>\n'
    xml += f'    <loc>{BASE_URL}/</loc>\n'
    xml += f'    <lastmod>{datetime.now().strftime("%Y-%m-%d")}</lastmod>\n'
    xml += '    <changefreq>daily</changefreq>\n'
    xml += '    <priority>1.0</priority>\n'
    xml += '  </url>\n'

    for shrine in shrines:
        link = shrine['link']
        date_str = shrine['published']
        
        xml += '  <url>\n'
        xml += f'    <loc>{BASE_URL}{link}</loc>\n'
        xml += f'    <lastmod>{date_str}</lastmod>\n'
        xml += '    <changefreq>weekly</changefreq>\n'
        xml += '    <priority>0.8</priority>\n'
        xml += '  </url>\n'
        
    xml += '</urlset>'
    return xml

def main():
    print("ğŸ”¨ ë¡œì»¬ ë§ˆí¬ë‹¤ìš´ ë°ì´í„° ë¹Œë“œ ì‹œì‘...")
    
    shrines = []
    
    os.makedirs(os.path.dirname(JSON_OUTPUT), exist_ok=True)
    os.makedirs(os.path.dirname(SITEMAP_OUTPUT), exist_ok=True)

    if not os.path.exists(CONTENT_DIR):
        os.makedirs(CONTENT_DIR)

    for filename in os.listdir(CONTENT_DIR):
        if not filename.endswith('.md'):
            continue
            
        filepath = os.path.join(CONTENT_DIR, filename)
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
                
                # Draft(ì´ˆì•ˆ) ê¸°ëŠ¥ (ì„ íƒ ì‚¬í•­)
                if post.get('draft') == True and not os.environ.get('DEV_MODE'):
                    continue

                if not post.get('lat') or not post.get('lng'):
                    continue

                date_val = post.get('date')
                if date_val:
                    published_date = str(date_val)
                else:
                    published_date = datetime.now().strftime('%Y-%m-%d')

                # [í•µì‹¬ ìˆ˜ì • ë¶€ë¶„] ìš”ì•½ë¬¸ ìƒì„± ë¡œì§ ê°œì„ 
                summary = post.get('summary')
                if not summary:
                    # ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì œê±° í›„ ì•ë¶€ë¶„ 120ìë§Œ ì¶”ì¶œ
                    clean_text = strip_markdown(post.content)
                    summary = clean_text[:120] + '...'
                
                shrine = {
                    "id": filename.replace('.md', ''),
                    "title": post.get('title', 'No Title'),
                    "lat": post.get('lat'),
                    "lng": post.get('lng'),
                    "categories": post.get('categories', []),
                    "thumbnail": post.get('thumbnail', '/static/images/default.png'),
                    "address": post.get('address', ''),
                    "published": published_date,
                    "summary": summary,  # ì •ì œëœ ìš”ì•½ë¬¸ ì‚¬ìš©
                    "link": f"/shrine/{filename.replace('.md', '')}" 
                }
                shrines.append(shrine)

        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ ({filename}): {e}")

    shrines.sort(key=lambda x: x['published'], reverse=True)

    final_data = {
        "last_updated": datetime.now().strftime("%Y.%m.%d"),
        "shrines": shrines
    }
    with open(JSON_OUTPUT, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    
    sitemap_content = generate_sitemap(shrines)
    with open(SITEMAP_OUTPUT, 'w', encoding='utf-8') as f:
        f.write(sitemap_content)

    print(f"\nğŸ‰ ë¹Œë“œ ì™„ë£Œ! ì´ {len(shrines)}ê°œ")

if __name__ == "__main__":
    main()